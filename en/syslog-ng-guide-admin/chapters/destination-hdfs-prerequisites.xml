<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE procedure
 [  <!ENTITY % entities SYSTEM "../../shared/syslog-ng-entities.ent">
 %entities;]>
<procedure xml:id="destination-hdfs-prerequisites" xmlns="http://docbook.org/ns/docbook" version="5.0" condition="ose">
    <title>Prerequisites</title>
    <para>To send messages from &abbrev; to HDFS, complete the following steps.</para>
    <formalpara>
        <title>Steps:</title>
        <para/>
    </formalpara>
    <step>
        <xi:include href="../../shared/chunk/para-java-requirements.xml" xmlns:xi="http://www.w3.org/2001/XInclude"/>
    </step>
    <step>
        <para>Download the Hadoop Distributed File System (HDFS) libraries (version 2.x) from <link xmlns:ns1="http://www.w3.org/1999/xlink" ns1:href="http://hadoop.apache.org/releases.html">http://hadoop.apache.org/releases.html</link>.</para>
    </step>
    <step>
        <para>Extract the HDFS libraries into a temporary directory, then collect the various <filename>.jar</filename> files into a single directory (for example, <filename>/opt/hadoop/lib/</filename>) where &abbrev; can access them. You must specify this directory in the &abbrev; configuration file. The files are located in the various <filename>lib</filename> directories under the <filename>share/</filename> directory of the Hadoop release package. (For example, in Hadoop 2.7, required files are <filename>common/hadoop-common-2.7.0.jar</filename>, <filename>common/libs/*.jar</filename>, <filename>hdfs/hadoop-hdfs-2.7.0.jar</filename>, <filename>hdfs/lib/*</filename>, but this may change between Hadoop releases, so it is easier to copy every <filename>.jar</filename> file into a single directory.</para>
    </step>
    <!-- The java home must be given at installation time for the PE installer. FIXME: include it in the PE installer description!  -->
</procedure>